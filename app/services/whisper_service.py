# import io
# from openai import OpenAI
# from app.config import settings
# from fastapi import UploadFile
# from typing import Optional
# import os

# client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# async def transcribe_audio(audio_file: UploadFile) -> str:
#     """
#     ÏóÖÎ°úÎìúÎêú Ïò§ÎîîÏò§ ÌååÏùºÏùÑ OpenAI Whisper Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôòÌï©ÎãàÎã§.
#     """
#     # ÌååÏùº ÌòïÏãù Ï≤¥ÌÅ¨
#     if audio_file.content_type and not audio_file.content_type.startswith("audio/"):
#         return "Error: Invalid audio file format."

#     try:
#         # 1. FastAPI UploadFileÏùÑ ÏùΩÏñ¥ÏÑú Î©îÎ™®Î¶¨(BytesIO)Ïóê Îã¥ÏäµÎãàÎã§.
#         audio_content = await audio_file.read()
#         audio_buffer = io.BytesIO(audio_content)
        
#         # 2. Whisper APIÎäî ÌååÏùº Ïù¥Î¶Ñ(ÌôïÏû•Ïûê)Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.
#         filename: Optional[str] = audio_file.filename
#         audio_buffer.name = filename if filename else "audio.wav"

#         # 3. OpenAI API Ìò∏Ï∂ú
#         # üö® [ÏàòÏ†ï] ÏãúÎØºÍ∂å ÏãúÌóòÏùÄ ÏòÅÏñ¥Î°ú ÏßÑÌñâÎêòÎØÄÎ°ú Ïñ∏Ïñ¥Î•º 'en'ÏúºÎ°ú Í≥†Ï†ïÌï©ÎãàÎã§.
#         # Ïù¥Î†áÍ≤å Ìï¥Ïïº ÏòÅÏñ¥Î•º ÌïúÍµ≠Ïñ¥Î°ú ÏñµÏßÄÎ°ú Î≤àÏó≠ÌïòÎäî Î¨∏Ï†úÎ•º ÎßâÏùÑ Ïàò ÏûàÏäµÎãàÎã§.
#         response = client.audio.transcriptions.create(
#             model="whisper-1",  
#             file=audio_buffer,
#             language="en" 
#         )
#         return response.text
#     except Exception as e:
#         print(f"Whisper API transcription failed: {e}")
#         return "Error: Speech recognition failed."


import io
import os
import requests
from fastapi import UploadFile
from typing import Optional

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

async def transcribe_audio(audio_file: UploadFile) -> str:

    if audio_file.content_type and not audio_file.content_type.startswith("audio/"):
        return "Error: Invalid audio file format."

    try:
        audio_bytes = await audio_file.read()
        audio_buffer = io.BytesIO(audio_bytes)
        audio_buffer.name = audio_file.filename or "audio.wav"

        files = {
            "file": (audio_buffer.name, audio_buffer, "application/octet-stream")
        }

        data = {
            "model": "whisper-1",
            "language": "en"
        }

        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}"
        }

        # üî• REST Î∞©ÏãùÏúºÎ°ú ÏßÅÏ†ë Whisper Ìò∏Ï∂ú
        response = requests.post(
            "https://api.openai.com/v1/audio/transcriptions",
            headers=headers,
            data=data,
            files=files,
            timeout=30
        )

        result = response.json()

        return result.get("text", "Error: No transcription returned.")

    except Exception as e:
        print(f"REST Whisper API failed: {e}")
        return "Error: Speech recognition failed."
