import io
from openai import OpenAI
from app.config import settings
from fastapi import UploadFile
from typing import Optional
import os

# ëª¨ë“  proxy ì œê±°
os.environ.pop("HTTP_PROXY", None)
os.environ.pop("HTTPS_PROXY", None)
os.environ.pop("http_proxy", None)
os.environ.pop("https_proxy", None)


# ğŸš¨ [ìˆ˜ì •] http_client=None ì¶”ê°€. ì´ê²ƒì´ proxies ì¶©ëŒì„ ë§‰ëŠ” í•µì‹¬ì…ë‹ˆë‹¤.
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    http_client=None 
) 
# Note: Render/RailwayëŠ” OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ë…¸ì¶œí•©ë‹ˆë‹¤.

async def transcribe_audio(audio_file: UploadFile) -> str:
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ OpenAI Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    # íŒŒì¼ í˜•ì‹ ì²´í¬
    if audio_file.content_type and not audio_file.content_type.startswith("audio/"):
        return "Error: Invalid audio file format."

    try:
        # 1. FastAPI UploadFileì„ ì½ì–´ì„œ ë©”ëª¨ë¦¬(BytesIO)ì— ë‹´ìŠµë‹ˆë‹¤.
        audio_content = await audio_file.read()
        audio_buffer = io.BytesIO(audio_content)
        
        # 2. Whisper APIëŠ” íŒŒì¼ ì´ë¦„(í™•ì¥ì)ì´ í•„ìš”í•©ë‹ˆë‹¤.
        filename: Optional[str] = audio_file.filename
        audio_buffer.name = filename if filename else "audio.wav"

        # 3. OpenAI API í˜¸ì¶œ
        # ğŸš¨ [ìˆ˜ì •] ì‹œë¯¼ê¶Œ ì‹œí—˜ì€ ì˜ì–´ë¡œ ì§„í–‰ë˜ë¯€ë¡œ ì–¸ì–´ë¥¼ 'en'ìœ¼ë¡œ ê³ ì •í•©ë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•´ì•¼ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ì–µì§€ë¡œ ë²ˆì—­í•˜ëŠ” ë¬¸ì œë¥¼ ë§‰ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        response = client.audio.transcriptions.create(
            model="whisper-1",  
            file=audio_buffer,
            language="en" 
        )
        return response.text
    except Exception as e:
        print(f"Whisper API transcription failed: {e}")
        return "Error: Speech recognition failed."